{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ASzdr1ujfqGO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import kagglehub\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFile\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True  # para manejar imágenes corruptas\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                           f1_score, confusion_matrix, roc_curve, auc,\n",
        "                           classification_report)\n",
        "import seaborn as sns\n",
        "import json\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import urllib.parse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# aplicar transformaciones\n",
        "class TransformSubset(torch.utils.data.Dataset):\n",
        "    def __init__(self, subset, transform=None):\n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.subset[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.subset)\n"
      ],
      "metadata": {
        "id": "zMaW2OeqlPKM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloaders\n",
        "def get_data_loaders(batch_size=64, test_ratio=0.2):\n",
        "\n",
        "    path = kagglehub.dataset_download(\n",
        "        \"bhavikjikadara/dog-and-cat-classification-dataset\"\n",
        "    )\n",
        "    print(\"Path to dataset files:\", path)\n",
        "\n",
        "    data_dir = os.path.join(path, \"PetImages\")\n",
        "\n",
        "    # transformaciones para la red pre-entrenada (cambia el tamaño 224x224)\n",
        "    train_transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.RandomCrop((224, 224)),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomRotation(15),\n",
        "            transforms.RandomAffine(\n",
        "                degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10\n",
        "            ),\n",
        "            transforms.ColorJitter(\n",
        "                brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1\n",
        "            ),\n",
        "            transforms.ToTensor(),\n",
        "            # Normalización estándar para redes preentrenadas de ImageNet\n",
        "            transforms.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "            ),\n",
        "            transforms.RandomErasing(p=0.1, scale=(0.02, 0.1), value=\"random\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    test_transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.CenterCrop((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    full_dataset = datasets.ImageFolder(root=data_dir, transform=None)\n",
        "    class_names = full_dataset.classes\n",
        "    print(\"Clases detectadas:\", class_names)\n",
        "\n",
        "    num_total = len(full_dataset)\n",
        "    num_test = int(num_total * test_ratio)\n",
        "    num_train = num_total - num_test\n",
        "\n",
        "    train_subset, test_subset = random_split(\n",
        "        full_dataset, [num_train, num_test]\n",
        "    )\n",
        "\n",
        "\n",
        "    train_dataset = TransformSubset(train_subset, transform=train_transform)\n",
        "    test_dataset = TransformSubset(test_subset, transform=test_transform)\n",
        "\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        pin_memory=False,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        pin_memory=False,\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader, class_names, train_transform, test_transform"
      ],
      "metadata": {
        "id": "34QYayTSllia"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modelo EfficientNet\n",
        "class gatoperroCNN_EfficientNet(nn.Module):\n",
        "    def __init__(self, num_classes=2, use_pretrained=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = models.efficientnet_b0(pretrained=use_pretrained)\n",
        "\n",
        "        for param in self.backbone.features[:5].parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        in_features = self.backbone.classifier[1].in_features\n",
        "\n",
        "        self.backbone.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(in_features, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)"
      ],
      "metadata": {
        "id": "tQ0R9_Fylcsh"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dispositivo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"usando el dispositivo:\", device)\n",
        "\n",
        "if device.type == \"cuda\":\n",
        "    print(\"nombre de la GPU:\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STzPxig8leo_",
        "outputId": "37bb29ab-6d19-42be-ddc6-ac82282f8984"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usando el dispositivo: cuda\n",
            "nombre de la GPU: NVIDIA A100-SXM4-80GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# función de evaluación\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            logits = model(images)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return correct / total if total > 0 else 0.0"
      ],
      "metadata": {
        "id": "pXde_iwXlPNX"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hiperparámetros y carpetas\n",
        "\n",
        "batch_size = 32  # batch más chico para EfficientNet\n",
        "epochs = 7\n",
        "learning_rate = 1e-4\n",
        "save_dir = \"folder_final_model\"\n",
        "\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# cargar datos\n",
        "print(\"\\ncargando datos...\")\n",
        "train_loader, test_loader, class_names, train_transform, test_transform = get_data_loaders(\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# inicializar modelo, optimizador y scheduler\n",
        "print(\"\\ninicializando modelo...\")\n",
        "model = gatoperroCNN_EfficientNet(num_classes=2, use_pretrained=True).to(device)\n",
        "print(\n",
        "    f\"modelo creado! \\nnúmero de parámetros: {sum(p.numel() for p in model.parameters()):,}\"\n",
        ")\n",
        "\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"parámetros entrenables: {trainable_params:,}\")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=learning_rate,\n",
        "    weight_decay=1e-4,  # Regularización L2\n",
        ")\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode=\"max\",  # Monitorear accuracy en test\n",
        "    patience=3,\n",
        "    factor=0.5,\n",
        ")\n",
        "\n",
        "# entrenamiento\n",
        "all_train_losses = []\n",
        "all_train_accs = []\n",
        "all_test_accs = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nepoch {epoch + 1}/{epochs} \")\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        correct_train += (preds == labels).sum().item()\n",
        "        total_train += labels.size(0)\n",
        "\n",
        "        if (batch_idx + 1) % 50 == 0:\n",
        "            print(\n",
        "                f\"batch {batch_idx + 1}/{len(train_loader)}, \"\n",
        "                f\"loss: {loss.item():.4f}\"\n",
        "            )\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_train_acc = correct_train / total_train\n",
        "    epoch_test_acc = evaluate(model, test_loader)\n",
        "\n",
        "    all_train_losses.append(epoch_loss)\n",
        "    all_train_accs.append(epoch_train_acc)\n",
        "    all_test_accs.append(epoch_test_acc)\n",
        "\n",
        "    # actualizar scheduler con métrica de validación\n",
        "    scheduler.step(epoch_test_acc)\n",
        "\n",
        "    print(f\"\\nresultados epoch {epoch + 1}:\")\n",
        "    print(f\"loss: {epoch_loss:.4f}\")\n",
        "    print(\n",
        "        f\"train accuracy: {epoch_train_acc:.4f} ({correct_train}/{total_train})\"\n",
        "    )\n",
        "    print(f\"test  accuracy: {epoch_test_acc:.4f}\")\n",
        "\n",
        "    # guardar checkpoint\n",
        "    checkpoint_path = os.path.join(save_dir, f\"model_epoch_{epoch + 1}.pth\")\n",
        "    torch.save(\n",
        "        {\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"loss\": epoch_loss,\n",
        "            \"train_acc\": epoch_train_acc,\n",
        "            \"test_acc\": epoch_test_acc,\n",
        "            \"train_losses\": all_train_losses,\n",
        "            \"train_accs\": all_train_accs,\n",
        "            \"test_accs\": all_test_accs,\n",
        "            \"class_names\": class_names,\n",
        "        },\n",
        "        checkpoint_path,\n",
        "    )\n",
        "    print(f\"modelo guardado en: {checkpoint_path}\")\n",
        "\n",
        "print(\"\\nentrenamiento: COMPLETADO!\")\n",
        "\n",
        "print(f\"\\nresumen de entrenamiento ({epochs} épocas):\")\n",
        "best_test_acc = max(all_test_accs)\n",
        "best_epoch = all_test_accs.index(best_test_acc) + 1\n",
        "print(f\"mejor accuracy en test: {best_test_acc:.4f} (época {best_epoch})\")\n",
        "print(f\"última loss: {all_train_losses[-1]:.4f}\")\n",
        "print(f\"última accuracy en train: {all_train_accs[-1]:.4f}\")\n",
        "print(f\"última accuracy en test: {all_test_accs[-1]:.4f}\")\n",
        "\n",
        "final_model_path = os.path.join(save_dir, \"model_final.pth\")\n",
        "torch.save(\n",
        "    {\n",
        "        \"epoch\": epochs,\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"train_losses\": all_train_losses,\n",
        "        \"train_accs\": all_train_accs,\n",
        "        \"test_accs\": all_test_accs,\n",
        "        \"class_names\": class_names,\n",
        "    },\n",
        "    final_model_path,\n",
        ")\n",
        "print(f\"\\nmodelo final guardado en: {final_model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt3QqY5VlMXL",
        "outputId": "42e8911d-826a-4d9b-f633-3ba54b48ba25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "cargando datos...\n",
            "Using Colab cache for faster access to the 'dog-and-cat-classification-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/dog-and-cat-classification-dataset\n",
            "Clases detectadas: ['Cat', 'Dog']\n",
            "\n",
            "inicializando modelo...\n",
            "modelo creado! \n",
            "número de parámetros: 4,335,998\n",
            "parámetros entrenables: 4,027,338\n",
            "\n",
            "epoch 1/7 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch 50/625, loss: 0.1255\n",
            "batch 100/625, loss: 0.1313\n",
            "batch 150/625, loss: 0.0335\n",
            "batch 200/625, loss: 0.1269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch 250/625, loss: 0.1290\n",
            "batch 300/625, loss: 0.0080\n",
            "batch 350/625, loss: 0.0214\n",
            "batch 400/625, loss: 0.1182\n",
            "batch 450/625, loss: 0.0804\n",
            "batch 500/625, loss: 0.0078\n",
            "batch 550/625, loss: 0.1483\n",
            "batch 600/625, loss: 0.0235\n",
            "\n",
            "resultados epoch 1:\n",
            "loss: 0.1067\n",
            "train accuracy: 0.9604 (19208/19999)\n",
            "test  accuracy: 0.9884\n",
            "modelo guardado en: folder_final_model/model_epoch_1.pth\n",
            "\n",
            "epoch 2/7 \n",
            "batch 50/625, loss: 0.1331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk1CmvHgnjjr"
      },
      "source": [
        "Graficar los resultados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVJeoRE7j92Q"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(1, epochs + 1), all_train_losses, 'b-', linewidth=2)\n",
        "plt.title('pérdida durante el entrenamiento')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHGL3kShxCx8"
      },
      "outputs": [],
      "source": [
        "# Gráfica combinada de accuracy en train y test\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(range(1, epochs + 1), all_train_accs, 'g-', linewidth=2, label='Train')\n",
        "plt.plot(range(1, epochs + 1), all_test_accs, 'r-', linewidth=2, label='Test')\n",
        "plt.title('Accuracy en Train y Test durante el entrenamiento', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Época', fontsize=12)\n",
        "plt.ylabel('Accuracy', fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(fontsize=12)\n",
        "plt.xticks(range(1, epochs + 1))\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(save_dir, \"training_accuracy_comparison.png\"))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqPTfiznj3PY"
      },
      "outputs": [],
      "source": [
        "# cargar y probar el mejor modelo\n",
        "best_epoch = all_test_accs.index(max(all_test_accs)) + 1\n",
        "best_model_path = os.path.join(save_dir, f\"model_epoch_{best_epoch}.pth\")\n",
        "\n",
        "print(f\"\\ncargando el mejor modelo (epoch {best_epoch})...\")\n",
        "checkpoint = torch.load(best_model_path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# Evaluar el mejor modelo\n",
        "final_test_acc = evaluate(model, test_loader)\n",
        "print(f\"accuracy del mejor modelo en test: {final_test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5oALD-uqUaR"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(model, test_loader, device, class_names=['Cat', 'Dog']):\n",
        "    # función para calcular todas las métricas de una\n",
        "    model.eval()\n",
        "\n",
        "    # almacenar predicciones y etiquetas reales\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    all_probabilities = []  # probabilidades para la clase positiva (perrito)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            logits = model(images)\n",
        "            probabilities = torch.softmax(logits, dim=1)\n",
        "\n",
        "            predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probabilities.extend(probabilities[:, 1].cpu().numpy())  # Probabilidad de ser perro\n",
        "\n",
        "    # pasar a numpy\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_probabilities = np.array(all_probabilities)\n",
        "\n",
        "\n",
        "    # métricas básiconas\n",
        "    # accuracy\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    # gato = 0 & perro = 1\n",
        "\n",
        "    precision_dog = precision_score(all_labels, all_predictions, pos_label=1)\n",
        "\n",
        "    # recall para perro\n",
        "    recall_dog = recall_score(all_labels, all_predictions, pos_label=1)\n",
        "\n",
        "    # F1-Score para perro\n",
        "    f1_dog = f1_score(all_labels, all_predictions, pos_label=1)\n",
        "\n",
        "    # Matriz de confusión\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "    # calcular specificity para gato (clase 0)\n",
        "    # specificity = TN / (TN + FP)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    specificity_cat = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "\n",
        "    # roc y área bajo la curva\n",
        "    fpr, tpr, thresholds = roc_curve(all_labels, all_probabilities, pos_label=1)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    optimal_idx = np.argmax(tpr - fpr)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "\n",
        "    # reporte automático\n",
        "    print(\"evaluación automática del modelo\")\n",
        "\n",
        "    print(f\"\\nconfiguración de clases:\")\n",
        "    print(f\"Clase 0: {class_names[0]}\")\n",
        "    print(f\"Clase 1: {class_names[1]}\")\n",
        "\n",
        "    print(f\"\\nmétricas básicas:\")\n",
        "    print(f\"accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "\n",
        "    # metas\n",
        "    accuracy_meta = 0.95\n",
        "    precision_meta = 0.93\n",
        "    recall_meta = 0.93\n",
        "    f1_meta = 0.93\n",
        "    specificity_meta = 0.93\n",
        "    auc_meta = 0.97\n",
        "\n",
        "    print(f\"\\nmetas establecidas\")\n",
        "    print(f\"exactitud mayor o igual a {accuracy_meta*100:.0f}%\")\n",
        "    print(f\"precisión (dog) mayor o igual a {precision_meta*100:.0f}%\")\n",
        "    print(f\"sensibility (dog) mayor o igual a {recall_meta*100:.0f}%\")\n",
        "    print(f\"F1-Score (dog) mayor o igual a {f1_meta*100:.0f}%\")\n",
        "    print(f\"specificity (cat) mayor o igual a {specificity_meta*100:.0f}%\")\n",
        "    print(f\"AUC-ROC: > {auc_meta}\")\n",
        "\n",
        "    print(f\"\\n\\nresultados obtenidos:\")\n",
        "\n",
        "    # Función para formatear resultados con iconos de cumplimiento\n",
        "    def formato_metrica(valor, meta, nombre):\n",
        "        cumplimiento = \"✅\" if valor >= meta else \"❌\"\n",
        "        porcentaje = f\"{valor*100:.2f}%\"\n",
        "        return f\"   {cumplimiento} {nombre}: {porcentaje} (Meta: ≥{meta*100:.0f}%)\"\n",
        "\n",
        "    print(formato_metrica(accuracy, accuracy_meta, \"exactitud\"))\n",
        "    print(formato_metrica(precision_dog, precision_meta, \"precisión (dog)\"))\n",
        "    print(formato_metrica(recall_dog, recall_meta, \"sensibility (dog)\"))\n",
        "    print(formato_metrica(f1_dog, f1_meta, \"F1 (dog)\"))\n",
        "    print(formato_metrica(specificity_cat, specificity_meta, \"specificity (cat)\"))\n",
        "    print(formato_metrica(roc_auc, auc_meta, \"AUC-ROC\"))\n",
        "\n",
        "\n",
        "    print(f\"\\n\\n reporte de clasificación:\")\n",
        "    print(classification_report(all_labels, all_predictions,\n",
        "                                target_names=class_names, digits=4))\n",
        "\n",
        "    # visualizaciones\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
        "    fig.suptitle('evaluación del modelo de clasificación',\n",
        "                 fontsize=16, fontweight='bold')\n",
        "\n",
        "    # 1 - matriz de confusión\n",
        "    ax1 = axes[0, 0]\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names, ax=ax1)\n",
        "    ax1.set_title('matriz de confusión', fontweight='bold')\n",
        "    ax1.set_xlabel('predicción')\n",
        "    ax1.set_ylabel('real')\n",
        "    ax1.text(0.5, -0.15, f'TP={tp}, TN={tn}, FP={fp}, FN={fn}',\n",
        "             ha='center', va='center', transform=ax1.transAxes, fontsize=10)\n",
        "\n",
        "    # 2 - métricas por clase\n",
        "    ax2 = axes[0, 1]\n",
        "    metrics_per_class = {\n",
        "        'precisión': [precision_score(all_labels, all_predictions, pos_label=0),\n",
        "                      precision_dog],\n",
        "        'sensibilidad': [recall_score(all_labels, all_predictions, pos_label=0),\n",
        "                         recall_dog],\n",
        "        'F1': [f1_score(all_labels, all_predictions, pos_label=0), f1_dog]\n",
        "    }\n",
        "\n",
        "    x = np.arange(len(class_names))\n",
        "    width = 0.25\n",
        "    multiplier = 0\n",
        "\n",
        "    for attribute, measurement in metrics_per_class.items():\n",
        "        offset = width * multiplier\n",
        "        rects = ax2.bar(x + offset, measurement, width, label=attribute)\n",
        "        ax2.bar_label(rects, padding=3, fmt='%.3f')\n",
        "        multiplier += 1\n",
        "\n",
        "    ax2.set_title('métricas por clase', fontweight='bold')\n",
        "    ax2.set_xlabel('clase')\n",
        "    ax2.set_ylabel('valor')\n",
        "    ax2.set_xticks(x + width, class_names)\n",
        "    ax2.legend(loc='upper right', ncol=3)\n",
        "    ax2.set_ylim(0, 1.1)\n",
        "\n",
        "    # 3 - curva roc\n",
        "    ax3 = axes[1,0]\n",
        "    ax3.plot(fpr, tpr, color='darkorange', lw=2,\n",
        "             label=f'curva ROC (AUC = {roc_auc:.4f})')\n",
        "    ax3.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
        "\n",
        "    ax3.plot(fpr[optimal_idx], tpr[optimal_idx], 'ro', markersize=10,\n",
        "             label=f'óptimo: {optimal_threshold:.3f}')\n",
        "\n",
        "    ax3.set_xlim([0.0, 1.0])\n",
        "    ax3.set_ylim([0.0, 1.05])\n",
        "    ax3.set_xlabel('tasa de falsos positivos')\n",
        "    ax3.set_ylabel('tasa de verdaderos positivos')\n",
        "    ax3.set_title('curva ROC', fontweight='bold')\n",
        "    ax3.legend(loc=\"lower right\")\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "\n",
        "    # 4 - distribución de probabilidades\n",
        "    ax4 = axes[1, 1]\n",
        "\n",
        "    # probabilidades por clase real\n",
        "    prob_dog_real_dog = all_probabilities[all_labels == 1]\n",
        "    prob_dog_real_cat = all_probabilities[all_labels == 0]\n",
        "\n",
        "    ax4.hist(prob_dog_real_cat, bins=30, alpha=0.7, label='Gatos Reales',\n",
        "             color='blue', density=True)\n",
        "    ax4.hist(prob_dog_real_dog, bins=30, alpha=0.7, label='Perros Reales',\n",
        "             color='red', density=True)\n",
        "\n",
        "    ax4.axvline(x=optimal_threshold, color='green', linestyle='--',\n",
        "                label=f'óptimo: {optimal_threshold:.3f}')\n",
        "\n",
        "    ax4.set_xlabel('probabilidad de ser perrito')\n",
        "    ax4.set_ylabel('densidad')\n",
        "    ax4.set_title('distribución de probabilidades', fontweight='bold')\n",
        "    ax4.legend()\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nresumen final\")\n",
        "\n",
        "    metricas = [accuracy, precision_dog, recall_dog, f1_dog, specificity_cat, roc_auc]\n",
        "    metas = [accuracy_meta, precision_meta, recall_meta, f1_meta, specificity_meta, auc_meta]\n",
        "\n",
        "    cumplimiento = sum(1 for m, meta in zip(metricas, metas) if m >= meta)\n",
        "    porcentaje_cumplimiento = (cumplimiento / len(metas)) * 100\n",
        "\n",
        "    total_metas = len(metas)\n",
        "    metas_cumplidas = cumplimiento\n",
        "\n",
        "    print(f\"\\ncalificación: {porcentaje_cumplimiento:.1f}%\")\n",
        "    print(f\"   ({metas_cumplidas} de {total_metas} metas cumplidas)\")\n",
        "\n",
        "    if porcentaje_cumplimiento == 100:\n",
        "        print(\"\\nse cumplieron todas las metas!! :)\")\n",
        "    elif porcentaje_cumplimiento >= 80:\n",
        "        print(\"\\nse cumple la mayoría de las metas.\")\n",
        "    elif porcentaje_cumplimiento >= 60:\n",
        "        print(\"\\nalgunas metas no se cumplieron\")\n",
        "    else:\n",
        "        print(\"\\nno se cumplieron la mayoría de las metas\")\n",
        "\n",
        "    metrics_dict = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision_dog': precision_dog,\n",
        "        'recall_dog': recall_dog,\n",
        "        'f1_dog': f1_dog,\n",
        "        'specificity_cat': specificity_cat,\n",
        "        'roc_auc': roc_auc,\n",
        "        'confusion_matrix': cm,\n",
        "        'roc_curve': (fpr, tpr, thresholds),\n",
        "        'optimal_threshold': optimal_threshold,\n",
        "        'all_predictions': all_predictions,\n",
        "        'all_labels': all_labels,\n",
        "        'all_probabilities': all_probabilities\n",
        "    }\n",
        "\n",
        "    return metrics_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-8QjCOy50Q-"
      },
      "outputs": [],
      "source": [
        "def evaluate_specific_image(model, image_path, transform, class_names, device):\n",
        "    from PIL import Image\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(img_tensor)\n",
        "        probabilities = torch.softmax(logits, dim=1)[0].cpu().numpy()\n",
        "        prediction = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    # imagen original\n",
        "    axes[0].imshow(img)\n",
        "    axes[0].axis('off')\n",
        "    axes[0].set_title('Imagen Original')\n",
        "\n",
        "    # probabilidades\n",
        "    colors = ['blue' if i == prediction else 'gray' for i in range(len(class_names))]\n",
        "    bars = axes[1].bar(class_names, probabilities, color=colors)\n",
        "    axes[1].set_ylim([0, 1])\n",
        "    axes[1].set_ylabel('Probabilidad')\n",
        "    axes[1].set_title('Probabilidades de Clasificación')\n",
        "\n",
        "    # Añadir valores en las barras\n",
        "    for bar, prob in zip(bars, probabilities):\n",
        "        height = bar.get_height()\n",
        "        axes[1].text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
        "                    f'{prob:.4f}', ha='center', va='bottom')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nresultado de clasificación:\")\n",
        "    print(f\"predicción: {class_names[prediction]} (confianza: {probabilities[prediction]:.4f})\")\n",
        "    print(f\"\\ndistribución de probabilidades:\")\n",
        "    for cls, prob in zip(class_names, probabilities):\n",
        "        print(f\"   {cls}: {prob:.4f}\")\n",
        "\n",
        "    return prediction, probabilities"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_image_from_url(model, image_url, transform, class_names, device):\n",
        "    try:\n",
        "        # Parsear la URL para obtener la URL real de la imagen\n",
        "        parsed_url = urllib.parse.urlparse(image_url)\n",
        "\n",
        "        # Si es una URL de Google Images, extraer la URL real\n",
        "        if 'google.com' in parsed_url.netloc and 'url=' in parsed_url.query:\n",
        "            query_params = urllib.parse.parse_qs(parsed_url.query)\n",
        "            if 'url' in query_params:\n",
        "                image_url = query_params['url'][0]\n",
        "\n",
        "        # Descargar la imagen\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "        response = requests.get(image_url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Abrir la imagen\n",
        "        img = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"error al descargar la imagen: {e} :(\")\n",
        "        return None, None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Preparar la imagen para el modelo\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    # Realizar predicción\n",
        "    with torch.no_grad():\n",
        "        logits = model(img_tensor)\n",
        "        probabilities = torch.softmax(logits, dim=1)[0].cpu().numpy()\n",
        "        prediction = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    # Crear visualización\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "    # Mostrar imagen original\n",
        "    axes[0].imshow(img)\n",
        "    axes[0].axis('off')\n",
        "    axes[0].set_title('imagen evaluada')\n",
        "\n",
        "    # Mostrar probabilidades\n",
        "    colors = ['green' if i == prediction else 'gray' for i in range(len(class_names))]\n",
        "    bars = axes[1].barh(class_names, probabilities, color=colors)\n",
        "    axes[1].set_xlim([0, 1])\n",
        "    axes[1].set_xlabel('probabilidad')\n",
        "    axes[1].set_title('probabilidades de Clasificación')\n",
        "    axes[1].grid(axis='x', alpha=0.3)\n",
        "\n",
        "    # Añadir valores de probabilidad\n",
        "    for bar, prob in zip(bars, probabilities):\n",
        "        width = bar.get_width()\n",
        "        axes[1].text(width + 0.01, bar.get_y() + bar.get_height()/2,\n",
        "                    f'{prob:.4f}', ha='left', va='center', fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Mostrar resultados en consola\n",
        "\n",
        "    print(\"\\nresultados:\")\n",
        "\n",
        "    print(f\"\\nse predice que esta imagen corresponde a un: {class_names[prediction]}\")\n",
        "    print(f\"con una confianza de: {probabilities[prediction]:.4f}\")\n",
        "    print(\"distribución completa de probabilidades:\")\n",
        "    for i, (cls, prob) in enumerate(zip(class_names, probabilities)):\n",
        "        print(f\"{i+1:2}. {cls:20}: {prob:.4f} {'★' if i == prediction else ''}\")\n",
        "\n",
        "\n",
        "    return prediction, probabilities"
      ],
      "metadata": {
        "id": "6ducSUH1dF75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cLM7A1_3e_5"
      },
      "source": [
        "Evaluación del modelo con las métricas establecidas en el reporte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bn5VTtP93P5G"
      },
      "outputs": [],
      "source": [
        "print(\"Cargando modelo entrenado...\")\n",
        "checkpoint_path = \"folder_final_model/model_final.pth\"\n",
        "\n",
        "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "model = gatoperroCNN_EfficientNet().to(device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "print(f\"modelo cargado desde: {checkpoint_path}\")\n",
        "print(f\"epochs entrenadas: {checkpoint.get('epoch', 'N/A')}\")\n",
        "print(f\"mejor accuracy en test: {max(checkpoint.get('test_accs', [0])):.4f}\")\n",
        "\n",
        "# cargar los dataloaders para laevaluación\n",
        "print(\"\\ncargando datos de prueba...\")\n",
        "_, test_loader, class_names, _, test_transform = get_data_loaders(batch_size=64)\n",
        "\n",
        "metrics = calculate_metrics(model, test_loader, device, class_names)\n",
        "\n",
        "# crear dataframe con métricas\n",
        "metrics_df = pd.DataFrame({\n",
        "        'métrica': ['accuracy', 'precision (dog)', 'recall (dog)',\n",
        "                   'F1-Score (dog)', 'specificity (cat)', 'AUC-ROC'],\n",
        "        'valor': [metrics['accuracy'], metrics['precision_dog'],\n",
        "                 metrics['recall_dog'], metrics['f1_dog'],\n",
        "                 metrics['specificity_cat'], metrics['roc_auc']],\n",
        "        'meta': [0.95, 0.93, 0.93, 0.93, 0.93, 0.97],\n",
        "        'cumple': ['✅' if metrics['accuracy'] >= 0.95 else '❌',\n",
        "                  '✅' if metrics['precision_dog'] >= 0.93 else '❌',\n",
        "                  '✅' if metrics['recall_dog'] >= 0.93 else '❌',\n",
        "                  '✅' if metrics['f1_dog'] >= 0.93 else '❌',\n",
        "                  '✅' if metrics['specificity_cat'] >= 0.93 else '❌',\n",
        "                  '✅' if metrics['roc_auc'] >= 0.97 else '❌']\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://image.europafm.com/clipping/cmsimages02/2020/03/04/DA7C101A-9CCC-4495-8AFD-EBEE80F76CC8/98.jpg?crop=669,376,x0,y43&width=1900&height=1069&optimize=low&format=webply\"\n",
        "prediction, probabilities = evaluate_image_from_url(\n",
        "        model=model,\n",
        "        image_url=image_url,\n",
        "        transform= test_transform,\n",
        "        class_names=class_names,\n",
        "        device=device)"
      ],
      "metadata": {
        "id": "gg9-0vEFfICc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://external-preview.redd.it/ZcEHQjokSliQDuwg2m7hpDjwy29WEypJIfzefqka8qY.gif?format=png8&s=b66f32e891806d0fc4cd3ee492ac8b4f8e6f47a5\"\n",
        "\n",
        "prediction, probabilities = evaluate_image_from_url(\n",
        "        model=model,\n",
        "        image_url=image_url,\n",
        "        transform= test_transform,\n",
        "        class_names=class_names,\n",
        "        device=device)"
      ],
      "metadata": {
        "id": "H-PjH8dVfz8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://images.ecestaticos.com/0Hpy1_mGylEw9puc5KzHG227wok=/0x0:1000x750/1200x900/filters:fill(white):format(jpg)/f.elconfidencial.com%2Foriginal%2F8ec%2Ffde%2Fa8b%2F8ecfdea8b0e364213f02fefe2c084cb5.jpg\"\n",
        "\n",
        "prediction, probabilities = evaluate_image_from_url(\n",
        "        model=model,\n",
        "        image_url=image_url,\n",
        "        transform= test_transform,\n",
        "        class_names=class_names,\n",
        "        device=device)"
      ],
      "metadata": {
        "id": "yX66ZHvcgp3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://cdn.mos.cms.futurecdn.net/CZPj6BF2ZaNchndwUjqdtQ.jpg\"\n",
        "prediction, probabilities = evaluate_image_from_url(\n",
        "        model=model,\n",
        "        image_url=image_url,\n",
        "        transform= test_transform,\n",
        "        class_names=class_names,\n",
        "        device=device)"
      ],
      "metadata": {
        "id": "9wD3jEGYgqhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://i.pinimg.com/originals/18/b3/14/18b3141b565855b626069f16e064f51b.gif\"\n",
        "prediction, probabilities = evaluate_image_from_url(\n",
        "        model=model,\n",
        "        image_url=image_url,\n",
        "        transform= test_transform,\n",
        "        class_names=class_names,\n",
        "        device=device)"
      ],
      "metadata": {
        "id": "DTkOg_Log7os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://preview.redd.it/3qel507lp1g31.png?auto=webp&s=7fc8f3b891d82389fe5183fa3a8c959efc685cea\"\n",
        "prediction, probabilities = evaluate_image_from_url(\n",
        "        model=model,\n",
        "        image_url=image_url,\n",
        "        transform= test_transform,\n",
        "        class_names=class_names,\n",
        "        device=device)"
      ],
      "metadata": {
        "id": "FPi1mE-sg-Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# guardar todo en csv's\n",
        "metrics_df.to_csv('metricas_evaluacion.csv', index=False)\n",
        "print(\"métricas guardadas en 'metricas_evaluacion.csv'\")\n",
        "\n",
        "np.savetxt('matriz_de_confusion.csv', metrics['confusion_matrix'], delimiter=',', fmt='%d')\n",
        "\n",
        "roc_data = np.column_stack(metrics['roc_curve'])\n",
        "np.savetxt('curva_roc.csv', roc_data, delimiter=',', header='FPR,TPR,Threshold', comments='')"
      ],
      "metadata": {
        "id": "pgP3_NcRbbpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nevaluación completada!\")"
      ],
      "metadata": {
        "id": "Atsgj9co5idq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar la carpeta"
      ],
      "metadata": {
        "id": "U11TniZXKida"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls -la\n",
        "\n",
        "nombre_carpeta = \"folder_final_model\"\n",
        "!zip -r {nombre_carpeta}.zip {nombre_carpeta}/\n",
        "from google.colab import files\n",
        "files.download(f'{nombre_carpeta}.zip')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "94Hl2GD8Kh3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r folder_final_model.zip /folder_final_model\n",
        "from google.colab import files\n",
        "files.download('folder_final_model.zip')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Gmk-M51JLC7C"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
